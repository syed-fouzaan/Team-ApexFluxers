{"ast":null,"code":"var _jsxFileName = \"D:\\\\nmit original\\\\gesture-react\\\\src\\\\WebcamFeed.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction WebcamFeed({\n  websocket,\n  selectedCase\n}) {\n  _s();\n  // We only need one ref for the canvas now\n  const canvasRef = useRef(null);\n  const frameIntervalRef = useRef(null);\n  // Use a ref to store the video stream itself for cleanup\n  const videoStreamRef = useRef(null);\n  useEffect(() => {\n    console.log('WebcamFeed: Initial mount effect running.');\n    // Function to start the webcam stream and draw to canvas\n    const startWebcam = async () => {\n      try {\n        console.log('WebcamFeed: Requesting webcam access...');\n        const stream = await navigator.mediaDevices.getUserMedia({\n          video: true\n        });\n        videoStreamRef.current = stream; // Store stream in ref for cleanup\n        console.log('WebcamFeed: Webcam stream obtained.');\n        const videoTrack = stream.getVideoTracks()[0];\n        const trackProcessor = new MediaStreamTrackProcessor(videoTrack);\n        const transformer = new TransformStream({\n          transform(videoFrame, controller) {\n            // Draw the current video frame onto the canvas for sending\n            if (canvasRef.current) {\n              const context = canvasRef.current.getContext('2d');\n              // Ensure canvas dimensions match video feed dimensions\n              if (canvasRef.current.width !== videoFrame.displayWidth || canvasRef.current.height !== videoFrame.displayHeight) {\n                canvasRef.current.width = videoFrame.displayWidth;\n                canvasRef.current.height = videoFrame.displayHeight;\n              }\n              // Draw the frame mirrored horizontally\n              context.save();\n              context.scale(-1, 1);\n              context.drawImage(videoFrame, -canvasRef.current.width, 0, canvasRef.current.width, canvasRef.current.height);\n              context.restore();\n            }\n            // Send the frame to the backend (handled in the other effect)\n            // We don't pass the frame through the transformer as we display the processed frame\n            videoFrame.close(); // Close the frame to free resources\n          }\n        });\n        trackProcessor.readable.pipeThrough(transformer);\n      } catch (err) {\n        console.error(\"WebcamFeed: Error accessing webcam:\", err);\n        alert(\"Could not access the webcam. Please ensure you have a camera connected and grant permission.\");\n      }\n    };\n    startWebcam();\n\n    // Cleanup function to stop the webcam stream and interval\n    return () => {\n      console.log('WebcamFeed: Cleaning up webcam stream and interval.');\n      if (videoStreamRef.current) {\n        const tracks = videoStreamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n      }\n      // Clear the interval using the ref\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n      }\n    };\n  }, []); // Empty dependency array means this effect runs only once on mount\n\n  useEffect(() => {\n    console.log('WebcamFeed: WebSocket or selectedCase changed. Checking conditions...');\n    console.log('WebcamFeed: websocket:', websocket, 'selectedCase:', selectedCase);\n\n    // Effect to send frames when WebSocket is connected and a case is selected\n    if (websocket && websocket.readyState === WebSocket.OPEN && selectedCase !== null) {\n      console.log(`WebcamFeed: Conditions met. Starting frame sending for case ${selectedCase}`);\n\n      // Clear any existing interval before starting a new one\n      if (frameIntervalRef.current) {\n        console.log('WebcamFeed: Clearing existing frame interval.');\n        clearInterval(frameIntervalRef.current);\n      }\n\n      // Store the new interval ID in the ref\n      frameIntervalRef.current = setInterval(() => {\n        if (canvasRef.current) {\n          // Get image data from the canvas as a Base64 data URL\n          // The canvas already has the current frame drawn by the first effect's transformer\n          const dataUrl = canvasRef.current.toDataURL('image/jpeg', 0.7); // Specify image format and quality\n\n          if (websocket && websocket.readyState === WebSocket.OPEN) {\n            // Send frame data as Base64 string\n            // console.log('WebcamFeed: Sending frame data...'); // Uncomment for noisy logging\n            websocket.send(JSON.stringify({\n              case: selectedCase,\n              frame: dataUrl // Send the Base64 data URL string\n            }));\n          } else {\n            console.log('WebcamFeed: Cannot send frame. WebSocket not ready.');\n          }\n        } else {\n          console.log('WebcamFeed: Cannot capture frame. canvasRef not ready.');\n        }\n      }, 100); // Send frame every 100ms (adjust as needed)\n\n      // Add WebSocket message listener here\n      websocket.onmessage = event => {\n        try {\n          const data = JSON.parse(event.data);\n          if (data.frame && canvasRef.current) {\n            // Received an annotated frame from the backend\n            const img = new Image();\n            img.onload = () => {\n              const context = canvasRef.current.getContext('2d');\n              // Draw the received image onto the canvas for display\n              // Ensure canvas size matches the received image size if necessary,\n              // or draw the image scaled to the current canvas size.\n              // For simplicity, let's assume backend sends frames at the canvas size.\n              context.drawImage(img, 0, 0, canvasRef.current.width, canvasRef.current.height);\n            };\n            img.src = 'data:image/jpeg;base64,' + data.frame;\n          }\n          // You can also handle other messages here, e.g., gesture names\n          // This part might be better handled in the parent App component\n          // and passed down as a prop if needed, but for now, we'll just log.\n          if (data.gesture) {\n            console.log(\"WebcamFeed: Received gesture:\", data.gesture);\n            // If you want to display gesture result here, you'd need a state/prop\n          }\n        } catch (e) {\n          console.error(\"WebcamFeed: Error parsing message from backend:\", e);\n        }\n      };\n    } else {\n      // Stop sending frames if WebSocket is not open or no case is selected\n      console.log(\"WebcamFeed: Conditions not met. Stopping frame sending.\");\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n        frameIntervalRef.current = null; // Reset interval ID\n      }\n      // Remove the message listener when conditions are not met\n      if (websocket) {\n        websocket.onmessage = null; // Or set to a default handler\n      }\n    }\n\n    // Cleanup function to clear the interval and message listener\n    return () => {\n      console.log('WebcamFeed: Cleanup effect running. Clearing frame interval and message listener.');\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n        frameIntervalRef.current = null; // Reset interval ID\n      }\n      if (websocket) {\n        websocket.onmessage = null; // Remove the message listener\n      }\n    };\n  }, [websocket, selectedCase]); // Effect runs when websocket or selectedCase changes\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      style: {\n        width: '100%',\n        height: 'auto'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 169,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 166,\n    columnNumber: 5\n  }, this);\n}\n_s(WebcamFeed, \"t8w5pN1pILO8QTnFZGMTGL1CHNs=\");\n_c = WebcamFeed;\nexport default WebcamFeed;\nvar _c;\n$RefreshReg$(_c, \"WebcamFeed\");","map":{"version":3,"names":["React","useRef","useEffect","jsxDEV","_jsxDEV","WebcamFeed","websocket","selectedCase","_s","canvasRef","frameIntervalRef","videoStreamRef","console","log","startWebcam","stream","navigator","mediaDevices","getUserMedia","video","current","videoTrack","getVideoTracks","trackProcessor","MediaStreamTrackProcessor","transformer","TransformStream","transform","videoFrame","controller","context","getContext","width","displayWidth","height","displayHeight","save","scale","drawImage","restore","close","readable","pipeThrough","err","error","alert","tracks","getTracks","forEach","track","stop","clearInterval","readyState","WebSocket","OPEN","setInterval","dataUrl","toDataURL","send","JSON","stringify","case","frame","onmessage","event","data","parse","img","Image","onload","src","gesture","e","children","ref","style","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["D:/nmit original/gesture-react/src/WebcamFeed.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\n\nfunction WebcamFeed({ websocket, selectedCase }) {\n  // We only need one ref for the canvas now\n  const canvasRef = useRef(null);\n  const frameIntervalRef = useRef(null);\n  // Use a ref to store the video stream itself for cleanup\n  const videoStreamRef = useRef(null);\n\n\n  useEffect(() => {\n    console.log('WebcamFeed: Initial mount effect running.');\n    // Function to start the webcam stream and draw to canvas\n    const startWebcam = async () => {\n      try {\n        console.log('WebcamFeed: Requesting webcam access...');\n        const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n        videoStreamRef.current = stream; // Store stream in ref for cleanup\n        console.log('WebcamFeed: Webcam stream obtained.');\n\n        const videoTrack = stream.getVideoTracks()[0];\n        const trackProcessor = new MediaStreamTrackProcessor(videoTrack);\n        const transformer = new TransformStream({\n            transform(videoFrame, controller) {\n                // Draw the current video frame onto the canvas for sending\n                if (canvasRef.current) {\n                    const context = canvasRef.current.getContext('2d');\n                    // Ensure canvas dimensions match video feed dimensions\n                    if (canvasRef.current.width !== videoFrame.displayWidth || canvasRef.current.height !== videoFrame.displayHeight) {\n                         canvasRef.current.width = videoFrame.displayWidth;\n                         canvasRef.current.height = videoFrame.displayHeight;\n                    }\n                    // Draw the frame mirrored horizontally\n                    context.save();\n                    context.scale(-1, 1);\n                    context.drawImage(videoFrame, -canvasRef.current.width, 0, canvasRef.current.width, canvasRef.current.height);\n                    context.restore();\n                }\n                // Send the frame to the backend (handled in the other effect)\n                // We don't pass the frame through the transformer as we display the processed frame\n                videoFrame.close(); // Close the frame to free resources\n            }\n        });\n\n        trackProcessor.readable.pipeThrough(transformer);\n\n\n      } catch (err) {\n        console.error(\"WebcamFeed: Error accessing webcam:\", err);\n        alert(\"Could not access the webcam. Please ensure you have a camera connected and grant permission.\");\n      }\n    };\n\n    startWebcam();\n\n    // Cleanup function to stop the webcam stream and interval\n    return () => {\n      console.log('WebcamFeed: Cleaning up webcam stream and interval.');\n      if (videoStreamRef.current) {\n        const tracks = videoStreamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n      }\n      // Clear the interval using the ref\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n      }\n    };\n  }, []); // Empty dependency array means this effect runs only once on mount\n\n  useEffect(() => {\n    console.log('WebcamFeed: WebSocket or selectedCase changed. Checking conditions...');\n    console.log('WebcamFeed: websocket:', websocket, 'selectedCase:', selectedCase);\n\n    // Effect to send frames when WebSocket is connected and a case is selected\n    if (websocket && websocket.readyState === WebSocket.OPEN && selectedCase !== null) {\n      console.log(`WebcamFeed: Conditions met. Starting frame sending for case ${selectedCase}`);\n\n      // Clear any existing interval before starting a new one\n      if (frameIntervalRef.current) {\n        console.log('WebcamFeed: Clearing existing frame interval.');\n        clearInterval(frameIntervalRef.current);\n      }\n\n      // Store the new interval ID in the ref\n      frameIntervalRef.current = setInterval(() => {\n        if (canvasRef.current) {\n          // Get image data from the canvas as a Base64 data URL\n          // The canvas already has the current frame drawn by the first effect's transformer\n          const dataUrl = canvasRef.current.toDataURL('image/jpeg', 0.7); // Specify image format and quality\n\n          if (websocket && websocket.readyState === WebSocket.OPEN) {\n             // Send frame data as Base64 string\n             // console.log('WebcamFeed: Sending frame data...'); // Uncomment for noisy logging\n             websocket.send(JSON.stringify({\n               case: selectedCase,\n               frame: dataUrl // Send the Base64 data URL string\n             }));\n          } else {\n              console.log('WebcamFeed: Cannot send frame. WebSocket not ready.');\n          }\n\n        } else {\n            console.log('WebcamFeed: Cannot capture frame. canvasRef not ready.');\n        }\n      }, 100); // Send frame every 100ms (adjust as needed)\n\n      // Add WebSocket message listener here\n      websocket.onmessage = (event) => {\n        try {\n          const data = JSON.parse(event.data);\n          if (data.frame && canvasRef.current) {\n            // Received an annotated frame from the backend\n            const img = new Image();\n            img.onload = () => {\n              const context = canvasRef.current.getContext('2d');\n              // Draw the received image onto the canvas for display\n              // Ensure canvas size matches the received image size if necessary,\n              // or draw the image scaled to the current canvas size.\n              // For simplicity, let's assume backend sends frames at the canvas size.\n              context.drawImage(img, 0, 0, canvasRef.current.width, canvasRef.current.height);\n            };\n            img.src = 'data:image/jpeg;base64,' + data.frame;\n          }\n          // You can also handle other messages here, e.g., gesture names\n          // This part might be better handled in the parent App component\n          // and passed down as a prop if needed, but for now, we'll just log.\n          if (data.gesture) {\n              console.log(\"WebcamFeed: Received gesture:\", data.gesture);\n              // If you want to display gesture result here, you'd need a state/prop\n          }\n\n        } catch (e) {\n          console.error(\"WebcamFeed: Error parsing message from backend:\", e);\n        }\n      };\n\n\n    } else {\n      // Stop sending frames if WebSocket is not open or no case is selected\n      console.log(\"WebcamFeed: Conditions not met. Stopping frame sending.\");\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n        frameIntervalRef.current = null; // Reset interval ID\n      }\n       // Remove the message listener when conditions are not met\n       if (websocket) {\n           websocket.onmessage = null; // Or set to a default handler\n       }\n    }\n\n    // Cleanup function to clear the interval and message listener\n    return () => {\n      console.log('WebcamFeed: Cleanup effect running. Clearing frame interval and message listener.');\n      if (frameIntervalRef.current) {\n        clearInterval(frameIntervalRef.current);\n        frameIntervalRef.current = null; // Reset interval ID\n      }\n      if (websocket) {\n          websocket.onmessage = null; // Remove the message listener\n      }\n    };\n\n  }, [websocket, selectedCase]); // Effect runs when websocket or selectedCase changes\n\n  return (\n    <div>\n      {/* The canvas element is used to display the processed feed */}\n      {/* Remove the display: 'none' style */}\n      <canvas ref={canvasRef} style={{ width: '100%', height: 'auto' }}></canvas>\n      {/* Remove the video element */}\n      {/* <video ref={videoRef} autoPlay playsInline style={{ width: '100%', height: 'auto' }}></video> */}\n    </div>\n  );\n}\n\nexport default WebcamFeed;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEjD,SAASC,UAAUA,CAAC;EAAEC,SAAS;EAAEC;AAAa,CAAC,EAAE;EAAAC,EAAA;EAC/C;EACA,MAAMC,SAAS,GAAGR,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMS,gBAAgB,GAAGT,MAAM,CAAC,IAAI,CAAC;EACrC;EACA,MAAMU,cAAc,GAAGV,MAAM,CAAC,IAAI,CAAC;EAGnCC,SAAS,CAAC,MAAM;IACdU,OAAO,CAACC,GAAG,CAAC,2CAA2C,CAAC;IACxD;IACA,MAAMC,WAAW,GAAG,MAAAA,CAAA,KAAY;MAC9B,IAAI;QACFF,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;QACtD,MAAME,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;UAAEC,KAAK,EAAE;QAAK,CAAC,CAAC;QACzER,cAAc,CAACS,OAAO,GAAGL,MAAM,CAAC,CAAC;QACjCH,OAAO,CAACC,GAAG,CAAC,qCAAqC,CAAC;QAElD,MAAMQ,UAAU,GAAGN,MAAM,CAACO,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7C,MAAMC,cAAc,GAAG,IAAIC,yBAAyB,CAACH,UAAU,CAAC;QAChE,MAAMI,WAAW,GAAG,IAAIC,eAAe,CAAC;UACpCC,SAASA,CAACC,UAAU,EAAEC,UAAU,EAAE;YAC9B;YACA,IAAIpB,SAAS,CAACW,OAAO,EAAE;cACnB,MAAMU,OAAO,GAAGrB,SAAS,CAACW,OAAO,CAACW,UAAU,CAAC,IAAI,CAAC;cAClD;cACA,IAAItB,SAAS,CAACW,OAAO,CAACY,KAAK,KAAKJ,UAAU,CAACK,YAAY,IAAIxB,SAAS,CAACW,OAAO,CAACc,MAAM,KAAKN,UAAU,CAACO,aAAa,EAAE;gBAC7G1B,SAAS,CAACW,OAAO,CAACY,KAAK,GAAGJ,UAAU,CAACK,YAAY;gBACjDxB,SAAS,CAACW,OAAO,CAACc,MAAM,GAAGN,UAAU,CAACO,aAAa;cACxD;cACA;cACAL,OAAO,CAACM,IAAI,CAAC,CAAC;cACdN,OAAO,CAACO,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;cACpBP,OAAO,CAACQ,SAAS,CAACV,UAAU,EAAE,CAACnB,SAAS,CAACW,OAAO,CAACY,KAAK,EAAE,CAAC,EAAEvB,SAAS,CAACW,OAAO,CAACY,KAAK,EAAEvB,SAAS,CAACW,OAAO,CAACc,MAAM,CAAC;cAC7GJ,OAAO,CAACS,OAAO,CAAC,CAAC;YACrB;YACA;YACA;YACAX,UAAU,CAACY,KAAK,CAAC,CAAC,CAAC,CAAC;UACxB;QACJ,CAAC,CAAC;QAEFjB,cAAc,CAACkB,QAAQ,CAACC,WAAW,CAACjB,WAAW,CAAC;MAGlD,CAAC,CAAC,OAAOkB,GAAG,EAAE;QACZ/B,OAAO,CAACgC,KAAK,CAAC,qCAAqC,EAAED,GAAG,CAAC;QACzDE,KAAK,CAAC,8FAA8F,CAAC;MACvG;IACF,CAAC;IAED/B,WAAW,CAAC,CAAC;;IAEb;IACA,OAAO,MAAM;MACXF,OAAO,CAACC,GAAG,CAAC,qDAAqD,CAAC;MAClE,IAAIF,cAAc,CAACS,OAAO,EAAE;QAC1B,MAAM0B,MAAM,GAAGnC,cAAc,CAACS,OAAO,CAAC2B,SAAS,CAAC,CAAC;QACjDD,MAAM,CAACE,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;MACvC;MACA;MACA,IAAIxC,gBAAgB,CAACU,OAAO,EAAE;QAC5B+B,aAAa,CAACzC,gBAAgB,CAACU,OAAO,CAAC;MACzC;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;;EAERlB,SAAS,CAAC,MAAM;IACdU,OAAO,CAACC,GAAG,CAAC,uEAAuE,CAAC;IACpFD,OAAO,CAACC,GAAG,CAAC,wBAAwB,EAAEP,SAAS,EAAE,eAAe,EAAEC,YAAY,CAAC;;IAE/E;IACA,IAAID,SAAS,IAAIA,SAAS,CAAC8C,UAAU,KAAKC,SAAS,CAACC,IAAI,IAAI/C,YAAY,KAAK,IAAI,EAAE;MACjFK,OAAO,CAACC,GAAG,CAAC,+DAA+DN,YAAY,EAAE,CAAC;;MAE1F;MACA,IAAIG,gBAAgB,CAACU,OAAO,EAAE;QAC5BR,OAAO,CAACC,GAAG,CAAC,+CAA+C,CAAC;QAC5DsC,aAAa,CAACzC,gBAAgB,CAACU,OAAO,CAAC;MACzC;;MAEA;MACAV,gBAAgB,CAACU,OAAO,GAAGmC,WAAW,CAAC,MAAM;QAC3C,IAAI9C,SAAS,CAACW,OAAO,EAAE;UACrB;UACA;UACA,MAAMoC,OAAO,GAAG/C,SAAS,CAACW,OAAO,CAACqC,SAAS,CAAC,YAAY,EAAE,GAAG,CAAC,CAAC,CAAC;;UAEhE,IAAInD,SAAS,IAAIA,SAAS,CAAC8C,UAAU,KAAKC,SAAS,CAACC,IAAI,EAAE;YACvD;YACA;YACAhD,SAAS,CAACoD,IAAI,CAACC,IAAI,CAACC,SAAS,CAAC;cAC5BC,IAAI,EAAEtD,YAAY;cAClBuD,KAAK,EAAEN,OAAO,CAAC;YACjB,CAAC,CAAC,CAAC;UACN,CAAC,MAAM;YACH5C,OAAO,CAACC,GAAG,CAAC,qDAAqD,CAAC;UACtE;QAEF,CAAC,MAAM;UACHD,OAAO,CAACC,GAAG,CAAC,wDAAwD,CAAC;QACzE;MACF,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC;;MAET;MACAP,SAAS,CAACyD,SAAS,GAAIC,KAAK,IAAK;QAC/B,IAAI;UACF,MAAMC,IAAI,GAAGN,IAAI,CAACO,KAAK,CAACF,KAAK,CAACC,IAAI,CAAC;UACnC,IAAIA,IAAI,CAACH,KAAK,IAAIrD,SAAS,CAACW,OAAO,EAAE;YACnC;YACA,MAAM+C,GAAG,GAAG,IAAIC,KAAK,CAAC,CAAC;YACvBD,GAAG,CAACE,MAAM,GAAG,MAAM;cACjB,MAAMvC,OAAO,GAAGrB,SAAS,CAACW,OAAO,CAACW,UAAU,CAAC,IAAI,CAAC;cAClD;cACA;cACA;cACA;cACAD,OAAO,CAACQ,SAAS,CAAC6B,GAAG,EAAE,CAAC,EAAE,CAAC,EAAE1D,SAAS,CAACW,OAAO,CAACY,KAAK,EAAEvB,SAAS,CAACW,OAAO,CAACc,MAAM,CAAC;YACjF,CAAC;YACDiC,GAAG,CAACG,GAAG,GAAG,yBAAyB,GAAGL,IAAI,CAACH,KAAK;UAClD;UACA;UACA;UACA;UACA,IAAIG,IAAI,CAACM,OAAO,EAAE;YACd3D,OAAO,CAACC,GAAG,CAAC,+BAA+B,EAAEoD,IAAI,CAACM,OAAO,CAAC;YAC1D;UACJ;QAEF,CAAC,CAAC,OAAOC,CAAC,EAAE;UACV5D,OAAO,CAACgC,KAAK,CAAC,iDAAiD,EAAE4B,CAAC,CAAC;QACrE;MACF,CAAC;IAGH,CAAC,MAAM;MACL;MACA5D,OAAO,CAACC,GAAG,CAAC,yDAAyD,CAAC;MACtE,IAAIH,gBAAgB,CAACU,OAAO,EAAE;QAC5B+B,aAAa,CAACzC,gBAAgB,CAACU,OAAO,CAAC;QACvCV,gBAAgB,CAACU,OAAO,GAAG,IAAI,CAAC,CAAC;MACnC;MACC;MACA,IAAId,SAAS,EAAE;QACXA,SAAS,CAACyD,SAAS,GAAG,IAAI,CAAC,CAAC;MAChC;IACH;;IAEA;IACA,OAAO,MAAM;MACXnD,OAAO,CAACC,GAAG,CAAC,mFAAmF,CAAC;MAChG,IAAIH,gBAAgB,CAACU,OAAO,EAAE;QAC5B+B,aAAa,CAACzC,gBAAgB,CAACU,OAAO,CAAC;QACvCV,gBAAgB,CAACU,OAAO,GAAG,IAAI,CAAC,CAAC;MACnC;MACA,IAAId,SAAS,EAAE;QACXA,SAAS,CAACyD,SAAS,GAAG,IAAI,CAAC,CAAC;MAChC;IACF,CAAC;EAEH,CAAC,EAAE,CAACzD,SAAS,EAAEC,YAAY,CAAC,CAAC,CAAC,CAAC;;EAE/B,oBACEH,OAAA;IAAAqE,QAAA,eAGErE,OAAA;MAAQsE,GAAG,EAAEjE,SAAU;MAACkE,KAAK,EAAE;QAAE3C,KAAK,EAAE,MAAM;QAAEE,MAAM,EAAE;MAAO;IAAE;MAAA0C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAS;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAGxE,CAAC;AAEV;AAACvE,EAAA,CA3KQH,UAAU;AAAA2E,EAAA,GAAV3E,UAAU;AA6KnB,eAAeA,UAAU;AAAC,IAAA2E,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}